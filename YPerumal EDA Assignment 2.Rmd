---
title: "EDA Assignment 2"
author: "Yevashan Perumal"
date: "14/04/2021"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r}
#Import Libaries
library(tidyverse)
library(ggrepel)
library(gridExtra)
```

```{r}
#Import Dat
# Data in same folder as this file
sup <-read_rds("./superbru-10k.Rds")
fixtures <- read_rds("./fixtures.rds")

head(sup)
head(fixtures)
dim(sup)
dim(fixtures)
```


```{r}
#Merge predictins and fixtures
df <- sup %>% left_join(fixtures,by='game_id')
dim(df)
head(df)
#Calculate prediction error
df <-df %>% mutate(prediction_error = abs(home_predicted_margin-result))

#correct results indicator
df <- df %>% mutate(correct_result = ifelse(home_predicted_margin>0 & result>0,1,
                                         ifelse(home_predicted_margin<0 & result<0,1,
                                         ifelse(home_predicted_margin==0 & result==0,1,
                                         0))))
```
```{r}
#points allocation function Superbru
points_alloc <- function(result,error){
    if(result==1 & error<=5){
        x<-15
    }else if(result==1 & error>5){
        x<-10
    }else if(result==0 & error<=5){
        x<-5
    }else{
        x<-0
    }
    return(x)
}

df['points_scored'] <- mapply(df$correct_result,df$home_predicted_margin,FUN=points_alloc)
head(df)
```
```{r}
    # Adding my own measure of prediction accuray, squared errors
#Punishes the degree which you were wrong more
df['squared_error'] <- (df$home_predicted_margin-df$result)^2
head(df)
```
```{r}
# Cumulative accuracy for each user after a game
df <- df %>% group_by(user_id)%>%
    arrange(user_id,game_id)%>%
    mutate(cumulative_score = cumsum(points_scored))%>%
    ungroup()

df <- df %>% group_by(user_id)%>%
    arrange(user_id,game_id)%>%
    mutate(cumulative_squared_error = cumsum(squared_error))%>%
    ungroup()
head(df)
```

```{r}
# Task 1
# If games are harder to predict, then prediction errors should be larger.Taking the mean prediction error per game, and then doing a boxplot allows us to find the outliersin terms of mean prediction error(and thus the games hardest to call)


is_outlier <- function(x) {
  return(x < quantile(x, 0.25) - 1.5 * IQR(x) | x > quantile(x, 0.75) + 1.5 * IQR(x))
}

b1 <-df %>% group_by(game_id)%>%
    summarise(mean_pred_error=mean(prediction_error))%>%
    mutate(outlier = ifelse(is_outlier(mean_pred_error), 
                            game_id,as.numeric(NA))) %>%
    ggplot(aes(x=1,y=mean_pred_error))+
    geom_boxplot()+
    geom_text_repel(aes(label=outlier),na.rm = TRUE)+
    labs(title = "Histogram of the Mean 
    Prediction Error Per Game")+
    ylab("Mean Prediction Error")+
    theme_minimal()

b2 <-df %>% group_by(game_id)%>%
    summarise(mean_sq_pred_error=sqrt(mean(squared_error)))%>%
    mutate(outlier = ifelse(is_outlier(mean_sq_pred_error), 
                            game_id,as.numeric(NA))) %>%
    ggplot(aes(x=1,y=mean_sq_pred_error))+
    geom_boxplot()+
    geom_text_repel(aes(label=outlier),na.rm = TRUE)+
    labs(title = "Histogram of the Mean
    Prediction Error Per Game")+
    ylab("RMSE")+
    theme_minimal()


grid.arrange(b1,b2,ncol=2)
head(df)
```

```{r}
#Task 2.1
#Leaderboard
#Do we need to print all twenty we get?
df %>%group_by(week,user_id)%>%
    summarise(max_score = max(cumulative_score))%>%
    mutate(rank = rank(max_score,ties.method="first"))%>%
    arrange(week,rank)%>%
    filter(rank<=20)
```


```{r}
# Task 2.2
#Code to return rank at any time
game_rank <- function(game_id_input,user_id_input){
    df %>%group_by(game_id,user_id)%>%
    summarise(max_score = max(cumulative_score))%>%
    mutate(rank = rank(max_score,ties.method="first"))%>%
    arrange(game_id,rank)%>%
    filter(user_id==user_id_input & game_id==game_id_input)
}
game_rank(game_id_input=2,user_id_input=2)

# Test if the rank stuff is working
```

```{r}
#Task 3
df %>% group_by(game_id)%>%
    mutate(mean_error = mean(prediction_error),med_erro=median(prediction_error))%>%
    ggplot(aes(x=game_id))+
    geom_line(aes(y=med_erro-mean_error))
    # geom_line(aes(y=med_erro))


# Do you calculate the mean and median errors before or after grouping?

# Looking at prediction errors?Or get mean and median predictions per game, 
# then get prediction errors? so the "crowd" and "average" users are like user_ids??
    
```


```{r}

head(df)
df <- 
df%>%mutate(fan_pred = ifelse(user_team_id==home | user_team_id==away,1,0))
head(df)

#Average error for fan predicted games should be lower?or Higher?

fans<-df%>%group_by(fan_pred)%>%
    summarise(mean_error = mean(prediction_error))

# T-Test? Different sample sizes?
```


```{r}


```

